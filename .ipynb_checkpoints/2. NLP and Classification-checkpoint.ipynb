{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform our Subreddits into Classification Model Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import brown, stopwords\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from nltk.tokenize.treebank import TreebankWordTokenizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>score</th>\n",
       "      <th>selftext</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>num_crossposts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>New Beyonce</td>\n",
       "      <td>1577854814</td>\n",
       "      <td>hiphopheads</td>\n",
       "      <td>1</td>\n",
       "      <td>check insta ðŸ¥³ðŸ–¤</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>MF Doom-Hoe Cakes</td>\n",
       "      <td>1577854884</td>\n",
       "      <td>hiphopheads</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>MF DOOM feat Ghostface Killah - Angels</td>\n",
       "      <td>1577855065</td>\n",
       "      <td>hiphopheads</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>[FRESH] TeeJayx6 - 2020</td>\n",
       "      <td>1577855147</td>\n",
       "      <td>hiphopheads</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Eminem &amp;amp; DJ Drama - Freestyle Part 1</td>\n",
       "      <td>1577855891</td>\n",
       "      <td>hiphopheads</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                     title  created_utc  \\\n",
       "0           0                               New Beyonce   1577854814   \n",
       "1           1                         MF Doom-Hoe Cakes   1577854884   \n",
       "2           2    MF DOOM feat Ghostface Killah - Angels   1577855065   \n",
       "3           3                   [FRESH] TeeJayx6 - 2020   1577855147   \n",
       "4           4  Eminem &amp; DJ Drama - Freestyle Part 1   1577855891   \n",
       "\n",
       "     subreddit  score        selftext  num_comments  num_crossposts  \n",
       "0  hiphopheads      1  check insta ðŸ¥³ðŸ–¤             1               0  \n",
       "1  hiphopheads      1             NaN             2               0  \n",
       "2  hiphopheads      1             NaN             0               0  \n",
       "3  hiphopheads      1             NaN            33               0  \n",
       "4  hiphopheads      1             NaN             0               0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = os.listdir('./data')\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for file in files:\n",
    "    \n",
    "    if file == '.ipynb_checkpoints':\n",
    "        pass\n",
    "    else:\n",
    "        df = pd.concat([df, pd.read_csv(f'./data/{file}', low_memory = False) ])\n",
    "        \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0            0\n",
       "title                 0\n",
       "created_utc           0\n",
       "subreddit             0\n",
       "score                 0\n",
       "selftext          52293\n",
       "num_comments          0\n",
       "num_crossposts        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check Nulls\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    0.873654\n",
       "True     0.126346\n",
       "Name: quality_post, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define Quality Post\n",
    "df.loc[:,'quality_post'] = (df['score'] > 2) | (df['num_comments'] > 2)\n",
    "df['quality_post'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>quality_post</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subreddit</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>hiphopheads</td>\n",
       "      <td>2.317263</td>\n",
       "      <td>12.953495</td>\n",
       "      <td>0.199691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>listentothis</td>\n",
       "      <td>1.164341</td>\n",
       "      <td>1.451618</td>\n",
       "      <td>0.050249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 score  num_comments  quality_post\n",
       "subreddit                                         \n",
       "hiphopheads   2.317263     12.953495      0.199691\n",
       "listentothis  1.164341      1.451618      0.050249"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subreddit Statistics\n",
    "df.groupby('subreddit').agg({'score': 'mean', 'num_comments':'mean', 'quality_post': 'mean'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subset of data for easier transformation\n",
    "data = df[['title', 'subreddit']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:376: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the corpus\n",
    "data.loc[:, \"tokenized\"] = data.loc[:,\"title\"].apply(nltk.word_tokenize)  #https://stackoverflow.com/questions/33098040/how-to-use-word-tokenize-in-data-frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatize\n",
    "\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return [lemmatizer.lemmatize(w) for w in text]\n",
    "\n",
    "data.loc[:,'lemmatized'] = data.loc[:,'tokenized'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:376: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "# Remove stopwords\n",
    "\n",
    "def remove_stopwords(df):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    return [text.lower() for text in df if text not in stop_words]  \n",
    "\n",
    "data.loc[:,'stop_words'] = data.loc[:,'lemmatized'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuation\n",
    "garbage = \"~`!@#$%^&*()_-+={[}]|\\:;'<,>.?/\"\n",
    "    \n",
    "data.loc[:,'cleaned'] = [[text for text in group if text not in garbage] for group in data.loc[:,'stop_words']]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn list into strings to input into model\n",
    "data.loc[:,'feature'] = [' '.join(x) for x in data.loc[:,'cleaned']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target Vector is predicting which subreddit the post came from\n",
    "y = data['subreddit']\n",
    "# Feature is the text from the title\n",
    "X = data['feature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hiphopheads     31674\n",
       "listentothis    30528\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Baseline Model\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split our Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline 1.1 Count Vectorizer and Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up our pipeline and parameters for gridsearch\n",
    "pipe = Pipeline([\n",
    "\n",
    "    ('cvec', CountVectorizer()),\n",
    "    (('lr'), LogisticRegression(solver = 'liblinear'))\n",
    "])\n",
    "\n",
    "pipe_params = {\n",
    "    \n",
    "    'cvec__max_features' : [1000, 2000, None],\n",
    "    'cvec__ngram_range'  : [(1,1), (1,2)],\n",
    "    'cvec__stop_words'   : ['english', None],\n",
    "    'cvec__min_df'       :  [1,2]  \n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate and fit our GridSearch\n",
    "gs = GridSearchCV(pipe,\n",
    "                 param_grid = pipe_params,\n",
    "                 cv = 5,\n",
    "                 n_jobs=3)\n",
    "\n",
    "gs.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score (Accuracy): 0.9863347190004823\n",
      "Testing score (Accuracy): 0.8836611114088205\n"
     ]
    }
   ],
   "source": [
    "# Training and Testing Acuracy Scores\n",
    "print('Training score (Accuracy): '+str(gs.score(X_train, y_train)))\n",
    "print('Testing score (Accuracy): '+str(gs.score(X_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Interpretation - Top 20 Words per Subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull coefficients from Estimator and Features from Transformer\n",
    "lr = gs.best_estimator_.named_steps['lr']\n",
    "cvec = gs.best_estimator_.named_steps['cvec']\n",
    "\n",
    "# Turn into DataFrames\n",
    "features_df = pd.DataFrame(lr.coef_.T,\n",
    "                           cvec.get_feature_names()\n",
    "                           , columns=['Importance'])\n",
    "top_20_hiphop = features_df.sort_values('Importance', ascending = True).head(20)\n",
    "top_20_listen = features_df.sort_values('Importance', ascending = False).head(20)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fresh</th>\n",
       "      <th>pop smoke</th>\n",
       "      <th>eminem</th>\n",
       "      <th>hype</th>\n",
       "      <th>original</th>\n",
       "      <th>thread</th>\n",
       "      <th>jay</th>\n",
       "      <th>drake</th>\n",
       "      <th>kanye</th>\n",
       "      <th>pete rock</th>\n",
       "      <th>rappers</th>\n",
       "      <th>albums</th>\n",
       "      <th>aesop rock</th>\n",
       "      <th>aesop</th>\n",
       "      <th>leak</th>\n",
       "      <th>rapper</th>\n",
       "      <th>nas</th>\n",
       "      <th>tupac</th>\n",
       "      <th>schoolboy</th>\n",
       "      <th>hop playlist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Importance</td>\n",
       "      <td>-4.404412</td>\n",
       "      <td>-3.213142</td>\n",
       "      <td>-2.521578</td>\n",
       "      <td>-2.223327</td>\n",
       "      <td>-2.119303</td>\n",
       "      <td>-2.098899</td>\n",
       "      <td>-2.063866</td>\n",
       "      <td>-2.027939</td>\n",
       "      <td>-1.999949</td>\n",
       "      <td>-1.997338</td>\n",
       "      <td>-1.964576</td>\n",
       "      <td>-1.944476</td>\n",
       "      <td>-1.903494</td>\n",
       "      <td>-1.902975</td>\n",
       "      <td>-1.869498</td>\n",
       "      <td>-1.837395</td>\n",
       "      <td>-1.817742</td>\n",
       "      <td>-1.77314</td>\n",
       "      <td>-1.731072</td>\n",
       "      <td>-1.722597</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               fresh  pop smoke    eminem      hype  original    thread  \\\n",
       "Importance -4.404412  -3.213142 -2.521578 -2.223327 -2.119303 -2.098899   \n",
       "\n",
       "                 jay     drake     kanye  pete rock   rappers    albums  \\\n",
       "Importance -2.063866 -2.027939 -1.999949  -1.997338 -1.964576 -1.944476   \n",
       "\n",
       "            aesop rock     aesop      leak    rapper       nas    tupac  \\\n",
       "Importance   -1.903494 -1.902975 -1.869498 -1.837395 -1.817742 -1.77314   \n",
       "\n",
       "            schoolboy  hop playlist  \n",
       "Importance  -1.731072     -1.722597  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# r/hiphopheads Top 20 Distinguishing Words\n",
    "top_20_hiphop.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>indie</th>\n",
       "      <th>folk</th>\n",
       "      <th>electronic</th>\n",
       "      <th>metal</th>\n",
       "      <th>pop</th>\n",
       "      <th>2019</th>\n",
       "      <th>2018</th>\n",
       "      <th>punk</th>\n",
       "      <th>liked youtube</th>\n",
       "      <th>2017</th>\n",
       "      <th>original song</th>\n",
       "      <th>alternative</th>\n",
       "      <th>rock</th>\n",
       "      <th>2014</th>\n",
       "      <th>band</th>\n",
       "      <th>ambient</th>\n",
       "      <th>techno</th>\n",
       "      <th>chillhop</th>\n",
       "      <th>2013</th>\n",
       "      <th>2016</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Importance</td>\n",
       "      <td>3.789652</td>\n",
       "      <td>3.071333</td>\n",
       "      <td>3.003983</td>\n",
       "      <td>2.88604</td>\n",
       "      <td>2.778851</td>\n",
       "      <td>2.684443</td>\n",
       "      <td>2.669384</td>\n",
       "      <td>2.666096</td>\n",
       "      <td>2.634973</td>\n",
       "      <td>2.521862</td>\n",
       "      <td>2.515557</td>\n",
       "      <td>2.475594</td>\n",
       "      <td>2.464409</td>\n",
       "      <td>2.411144</td>\n",
       "      <td>2.35839</td>\n",
       "      <td>2.35551</td>\n",
       "      <td>2.251942</td>\n",
       "      <td>2.225665</td>\n",
       "      <td>2.068627</td>\n",
       "      <td>2.028744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               indie      folk  electronic    metal       pop      2019  \\\n",
       "Importance  3.789652  3.071333    3.003983  2.88604  2.778851  2.684443   \n",
       "\n",
       "                2018      punk  liked youtube      2017  original song  \\\n",
       "Importance  2.669384  2.666096       2.634973  2.521862       2.515557   \n",
       "\n",
       "            alternative      rock      2014     band  ambient    techno  \\\n",
       "Importance     2.475594  2.464409  2.411144  2.35839  2.35551  2.251942   \n",
       "\n",
       "            chillhop      2013      2016  \n",
       "Importance  2.225665  2.068627  2.028744  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# r/listentothis Top 20 Distinguishing Words\n",
    "top_20_listen.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Predictions for Confusion Matrix\n",
    "X_transform = cvec.transform(X_test)\n",
    "y_pred = lr.predict(X_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8836611114088205\n",
      "Sensitivity: 0.8442221980650071\n",
      "Specificity: 0.922003804692454\n",
      "Precision: 0.9132173095014111\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "# Print Scores\n",
    "print(\"Accuracy: \" + str((tp + tn) / (tp + tn + fp + fn)))\n",
    "print(\"Sensitivity: \" + str((tp) / (tp + fn)))\n",
    "print(\"Specificity: \" + str((tn) / (tn + fp)))\n",
    "print(\"Precision: \" + str((tp) / (tp + fp )))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline 1.2  TF-IDF Vectorizer and Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up pipeline\n",
    "pipe = Pipeline([\n",
    "\n",
    "    ('tvec', TfidfVectorizer()),\n",
    "    (('lr'), LogisticRegression(solver = 'liblinear'))\n",
    "])\n",
    "\n",
    "# Parameters for GridSearch\n",
    "pipe_params = {\n",
    "    \n",
    "    'tvec__max_features' : [2000,3000,4000,5000,None],\n",
    "    'tvec__ngram_range'  : [(1,1), (1,2)],\n",
    "    'tvec__stop_words'   : ['english', None],\n",
    "    'tvec__min_df'       :  (2,5),\n",
    "    'tvec__max_df'       : (0.75, 0.95)\n",
    "    \n",
    "    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate and fit our Gridsearch\n",
    "gs = GridSearchCV(pipe,\n",
    "                 param_grid = pipe_params,\n",
    "                 cv = 5,\n",
    "                 n_jobs=3)\n",
    "\n",
    "gs.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9306630532142119\n",
      "Testing Accuracy: 0.8811424896843685\n"
     ]
    }
   ],
   "source": [
    "print('Training Accuracy: ' + str(gs.score(X_train, y_train)))\n",
    "print('Testing Accuracy: ' + str(gs.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull coefficients from Estimator and Features from Transformer\n",
    "lr = gs.best_estimator_.named_steps['lr']\n",
    "tvec = gs.best_estimator_.named_steps['tvec']\n",
    "\n",
    "\n",
    "#turn it into a data frame\n",
    "features_df = pd.DataFrame(lr.coef_.T,\n",
    "                           tvec.get_feature_names()\n",
    "                           , columns=['Importance'])\n",
    "top_20_hiphop = features_df.sort_values('Importance', ascending = True).head(20)\n",
    "top_20_listen = features_df.sort_values('Importance', ascending = False).head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Interpretation - Top 20 Words per Subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fresh</th>\n",
       "      <th>eminem</th>\n",
       "      <th>original</th>\n",
       "      <th>pop smoke</th>\n",
       "      <th>lil</th>\n",
       "      <th>album</th>\n",
       "      <th>rapper</th>\n",
       "      <th>jay</th>\n",
       "      <th>drake</th>\n",
       "      <th>kanye</th>\n",
       "      <th>feat</th>\n",
       "      <th>hype</th>\n",
       "      <th>smoke</th>\n",
       "      <th>leak</th>\n",
       "      <th>ft</th>\n",
       "      <th>thread</th>\n",
       "      <th>kendrick</th>\n",
       "      <th>top</th>\n",
       "      <th>future</th>\n",
       "      <th>fresh video</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Importance</td>\n",
       "      <td>-15.511374</td>\n",
       "      <td>-5.518547</td>\n",
       "      <td>-4.887793</td>\n",
       "      <td>-4.813343</td>\n",
       "      <td>-4.752123</td>\n",
       "      <td>-4.720969</td>\n",
       "      <td>-4.699521</td>\n",
       "      <td>-4.347822</td>\n",
       "      <td>-4.06415</td>\n",
       "      <td>-3.619456</td>\n",
       "      <td>-3.445985</td>\n",
       "      <td>-3.444556</td>\n",
       "      <td>-3.413657</td>\n",
       "      <td>-3.412053</td>\n",
       "      <td>-3.359101</td>\n",
       "      <td>-3.168982</td>\n",
       "      <td>-3.065876</td>\n",
       "      <td>-2.938429</td>\n",
       "      <td>-2.846222</td>\n",
       "      <td>-2.841309</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                fresh    eminem  original  pop smoke       lil     album  \\\n",
       "Importance -15.511374 -5.518547 -4.887793  -4.813343 -4.752123 -4.720969   \n",
       "\n",
       "              rapper       jay    drake     kanye      feat      hype  \\\n",
       "Importance -4.699521 -4.347822 -4.06415 -3.619456 -3.445985 -3.444556   \n",
       "\n",
       "               smoke      leak        ft    thread  kendrick       top  \\\n",
       "Importance -3.413657 -3.412053 -3.359101 -3.168982 -3.065876 -2.938429   \n",
       "\n",
       "              future  fresh video  \n",
       "Importance -2.846222    -2.841309  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# r/hiphopheads top 20 words\n",
    "top_20_hiphop.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>indie</th>\n",
       "      <th>2020</th>\n",
       "      <th>2019</th>\n",
       "      <th>rock</th>\n",
       "      <th>pop</th>\n",
       "      <th>electronic</th>\n",
       "      <th>folk</th>\n",
       "      <th>2018</th>\n",
       "      <th>metal</th>\n",
       "      <th>punk</th>\n",
       "      <th>alternative</th>\n",
       "      <th>2017</th>\n",
       "      <th>jazz</th>\n",
       "      <th>band</th>\n",
       "      <th>house</th>\n",
       "      <th>liked youtube</th>\n",
       "      <th>2016</th>\n",
       "      <th>hop 2020</th>\n",
       "      <th>2015</th>\n",
       "      <th>2014</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Importance</td>\n",
       "      <td>10.546029</td>\n",
       "      <td>10.063975</td>\n",
       "      <td>9.808461</td>\n",
       "      <td>9.800317</td>\n",
       "      <td>8.503466</td>\n",
       "      <td>7.041222</td>\n",
       "      <td>6.693268</td>\n",
       "      <td>6.510102</td>\n",
       "      <td>6.456165</td>\n",
       "      <td>6.367025</td>\n",
       "      <td>6.17211</td>\n",
       "      <td>5.225184</td>\n",
       "      <td>4.917715</td>\n",
       "      <td>4.758196</td>\n",
       "      <td>4.636138</td>\n",
       "      <td>4.329111</td>\n",
       "      <td>4.215458</td>\n",
       "      <td>4.143717</td>\n",
       "      <td>3.987855</td>\n",
       "      <td>3.956869</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                indie       2020      2019      rock       pop  electronic  \\\n",
       "Importance  10.546029  10.063975  9.808461  9.800317  8.503466    7.041222   \n",
       "\n",
       "                folk      2018     metal      punk  alternative      2017  \\\n",
       "Importance  6.693268  6.510102  6.456165  6.367025      6.17211  5.225184   \n",
       "\n",
       "                jazz      band     house  liked youtube      2016  hop 2020  \\\n",
       "Importance  4.917715  4.758196  4.636138       4.329111  4.215458  4.143717   \n",
       "\n",
       "                2015      2014  \n",
       "Importance  3.987855  3.956869  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# r/listentothis top 20 words\n",
    "top_20_listen.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.DataFrame()\n",
    "combined.loc[:, 'r/hiphopheads'] = top_20_hiphop.index.to_list()\n",
    "combined.loc[:, 'r/listentothis'] = top_20_listen.index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r/hiphopheads</th>\n",
       "      <th>r/listentothis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>fresh</td>\n",
       "      <td>indie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>eminem</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>original</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>pop smoke</td>\n",
       "      <td>rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>lil</td>\n",
       "      <td>pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>album</td>\n",
       "      <td>electronic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>rapper</td>\n",
       "      <td>folk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>jay</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>drake</td>\n",
       "      <td>metal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>kanye</td>\n",
       "      <td>punk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>feat</td>\n",
       "      <td>alternative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>hype</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>smoke</td>\n",
       "      <td>jazz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>leak</td>\n",
       "      <td>band</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>ft</td>\n",
       "      <td>house</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>thread</td>\n",
       "      <td>liked youtube</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>kendrick</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>top</td>\n",
       "      <td>hop 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>future</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>fresh video</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   r/hiphopheads r/listentothis\n",
       "0          fresh          indie\n",
       "1         eminem           2020\n",
       "2       original           2019\n",
       "3      pop smoke           rock\n",
       "4            lil            pop\n",
       "5          album     electronic\n",
       "6         rapper           folk\n",
       "7            jay           2018\n",
       "8          drake          metal\n",
       "9          kanye           punk\n",
       "10          feat    alternative\n",
       "11          hype           2017\n",
       "12         smoke           jazz\n",
       "13          leak           band\n",
       "14            ft          house\n",
       "15        thread  liked youtube\n",
       "16      kendrick           2016\n",
       "17           top       hop 2020\n",
       "18        future           2015\n",
       "19   fresh video           2014"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Predictions for Confusion Matrix\n",
    "X_transform = tvec.transform(X_test)\n",
    "y_pred = lr.predict(X_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8811424896843685\n",
      "Sensitivity: 0.8395477769322752\n",
      "Specificity: 0.9215810610864511\n",
      "Precision: 0.9123449497932664\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "# Print Scores\n",
    "print(\"Accuracy: \" + str((tp + tn) / (tp + tn + fp + fn)))\n",
    "print(\"Sensitivity: \" + str((tp) / (tp + fn)))\n",
    "print(\"Specificity: \" + str((tn) / (tn + fp)))\n",
    "print(\"Precision: \" + str((tp) / (tp + fp )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
